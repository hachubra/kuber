# Домашнее задание к занятию «Как работает сеть в K8s»

### Цель задания

Настроить сетевую политику доступа к подам.

### Чеклист готовности к домашнему заданию

1. Кластер K8s с установленным сетевым плагином Calico.

### Инструменты и дополнительные материалы, которые пригодятся для выполнения задания

1. [Документация Calico](https://www.tigera.io/project-calico/).
2. [Network Policy](https://kubernetes.io/docs/concepts/services-networking/network-policies/).
3. [About Network Policy](https://docs.projectcalico.org/about/about-network-policy).

-----

### Задание 1. Создать сетевую политику или несколько политик для обеспечения доступа

1. Создать deployment'ы приложений frontend, backend и cache и соответсвующие сервисы.
2. В качестве образа использовать network-multitool.
3. Разместить поды в namespace App.
4. Создать политики, чтобы обеспечить доступ frontend -> backend -> cache. Другие виды подключений должны быть запрещены.
5. Продемонстрировать, что трафик разрешён и запрещён.



#### Решение 1.

Deployment.yaml:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend  
  namespace: app
  labels:
    app: frontend
spec:
  replicas: 1
  selector:
    matchLabels:
      app: front
  template:
    metadata:
      labels:
        app: front
    spec:
      containers:
      - name: wbitt
        image: wbitt/network-multitool
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: back
  namespace: app
  labels:
    app: backend
spec:
  replicas: 1
  selector:
    matchLabels:
      app: back
  template:
    metadata:
      labels:
        app: back
    spec:
      containers:
      - name: wbitt
        image: wbitt/network-multitool
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cash
  namespace: app
  labels:
    app: cache
spec:
  replicas: 1
  selector:
    matchLabels:
      app: cash
  template:
    metadata:
      labels:
        app: cash
    spec:
      containers:
      - name: wbitt
        image: wbitt/network-multitool

```

Service.yaml:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: front-svc
spec:
  ports:
  - name: front
    port: 80
    protocol: TCP
    targetPort: 80
  selector:
    app: front

---
apiVersion: v1
kind: Service
metadata:
  name: back-svc
spec:
  ports:
  - name: back
    port: 80
    protocol: TCP
    targetPort: 80
  selector:
    app: back

---

apiVersion: v1
kind: Service
metadata:
  name: cache-svc
spec:
  ports:
  - name: cash
    port: 80
    protocol: TCP
    targetPort: 80
  selector:
    app: cash
```

Развертывание:

Создаем namespace:

```bash
alex@ubu04:~/kuber2025/3.3$ kubectl create namespace app
namespace/app created
```
Deploy:

```bash
alex@ubu04:~/kuber2025/3.3$ kubectl apply -f Deployment.yaml 
deployment.apps/frontend created
deployment.apps/back created
deployment.apps/cash created
```

```bash
alex@ubu04:~/kuber2025/3.3$ kubectl get svc -n app -o wide
NAME        TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE   SELECTOR
back-svc    ClusterIP   10.152.183.130   <none>        80/TCP    70s   app=back
cache-svc   ClusterIP   10.152.183.151   <none>        80/TCP    70s   app=cash
front-svc   ClusterIP   10.152.183.115   <none>        80/TCP    70s   app=front
```
```bash
alex@ubu04:~/kuber2025/3.3$ kubectl get po -n app -o wide
NAME                       READY   STATUS    RESTARTS   AGE   IP             NODE    NOMINATED NODE   READINESS GATES
back-865bc4f459-tc5hs      1/1     Running   0          16m   10.1.140.117   ubu04   <none>           <none>
cash-684b858975-989l5      1/1     Running   0          16m   10.1.140.88    ubu04   <none>           <none>
frontend-68c5645c5-qcx6s   1/1     Running   0          16m   10.1.140.118   ubu04   <none>           <none>
```

Проверка работы:

```bash
kubectl exec -n app deployments/frontend -it -- bash
```
к поду:
```bash
busybox         chown           dmesg           egrep           getopt          ionice          linux32         lzop            mount           nisdomainname   printenv        rmdir           sh              sync            uname           zcat            
frontend-68c5645c5-qcx6s:/# curl http://10.1.140.117
WBITT Network MultiTool (with NGINX) - back-865bc4f459-tc5hs - 10.1.140.117 - HTTP: 80 , HTTPS: 443 . (Formerly praqma/network-multitool)
```
к сервису:
```bash
frontend-68c5645c5-qcx6s:/# curl http://10.152.183.130
WBITT Network MultiTool (with NGINX) - back-865bc4f459-tc5hs - 10.1.140.117 - HTTP: 80 , HTTPS: 443 . (Formerly praqma/network-multitool)
```

Network Policy:

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: front-back
  namespace: app # Optional, defaults to the namespace where applied
spec:
  podSelector:
    matchLabels:
      app: backend # Selects pods based on labels
  policyTypes:
    - Ingress # Applies to incoming traffic
  ingress: # Rules for incoming traffic
    - from:
        - podSelector:
            matchLabels:
              app: front # Allow traffic from pods with these labels

---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: front-back
  namespace: app # Optional, defaults to the namespace where applied
spec:
  podSelector:
    matchLabels:
      app: backend # Selects pods based on labels
  policyTypes:
    - Ingress # Applies to incoming traffic
  ingress: # Rules for incoming traffic
    - from:
        - podSelector:
            matchLabels:
              app: front # Allow traffic from pods with these labels

---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: back-cache
  namespace: app # Optional, defaults to the namespace where applied
spec:
  podSelector:
    matchLabels:
      app: cash # Selects pods based on labels
  policyTypes:
    - Ingress # Applies to incoming traffic
  ingress: # Rules for incoming traffic
    - from:
        - podSelector:
            matchLabels:
              app: back # Allow traffic from pods with these labels
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: deny-policy
  namespace: app # Optional, defaults to the namespace where applied
spec:
  podSelector:
    matchLabels:
      app: front # Selects pods based on labels
  policyTypes:
    - Ingress # Applies to incoming traffic

```

Применение политик:

```bash
alex@ubu04:~/kuber2025/3.3$ kubectl apply -f NetPolicy.yaml -n app
networkpolicy.networking.k8s.io/front-back unchanged
networkpolicy.networking.k8s.io/back-cache unchanged
networkpolicy.networking.k8s.io/deny-policy created
```

```bash
alex@ubu04:~/kuber2025/3.3$ kubectl get networkpolicies.networking.k8s.io -n app
NAME          POD-SELECTOR   AGE
back-cache    app=cash       13m
deny-policy   <none>         57s
front-back    app=backend    13m
```

Демонстрация работы сетевых политик:

1. подключаемся в frontend и проверяем доступ к backend

```bash
alex@ubu04:~/kuber2025/3.3$ kubectl exec -n app deployments/frontend -it -- bash
```
```bash
frontend-68c5645c5-qcx6s:/# curl http://10.1.140.117
WBITT Network MultiTool (with NGINX) - back-865bc4f459-tc5hs - 10.1.140.117 - HTTP: 80 , HTTPS: 443 . (Formerly praqma/network-multitool)
frontend-68c5645c5-qcx6s:/# curl http://10.152.183.130
WBITT Network MultiTool (with NGINX) - back-865bc4f459-tc5hs - 10.1.140.117 - HTTP: 80 , HTTPS: 443 . (Formerly praqma/network-multitool)
```
Убеждаемся, что доступа от frontend к cache нет:

```bash
frontend-68c5645c5-qcx6s:/# curl http://10.152.183.151
^C
frontend-68c5645c5-qcx6s:/# curl http://10.1.140.88
^C
```

2. подключаемся в backend и проверяем доступ к cache

```bash
alex@ubu04:~/kuber2025/3.3$ kubectl exec -n app deployments/back -it -- bash
```
```bash
back-865bc4f459-tc5hs:/# curl http://10.152.183.151
WBITT Network MultiTool (with NGINX) - cash-684b858975-989l5 - 10.1.140.88 - HTTP: 80 , HTTPS: 443 . (Formerly praqma/network-multitool)
back-865bc4f459-tc5hs:/# curl http://10.1.140.88
WBITT Network MultiTool (with NGINX) - cash-684b858975-989l5 - 10.1.140.88 - HTTP: 80 , HTTPS: 443 . (Formerly praqma/network-multitool)
back-865bc4f459-tc5hs:/# 
```


Убеждаемся, что доступа к frontend  нет:

```bash
back-865bc4f459-tc5hs:/# curl http://10.152.183.115
^C
back-865bc4f459-tc5hs:/# 
```

---

### Правила приёма работы

1. Домашняя работа оформляется в своём Git-репозитории в файле README.md. Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.
2. Файл README.md должен содержать скриншоты вывода необходимых команд, а также скриншоты результатов.
3. Репозиторий должен содержать тексты манифестов или ссылки на них в файле README.md.
